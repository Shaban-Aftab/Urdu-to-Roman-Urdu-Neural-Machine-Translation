{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjCF_ehp8lQw"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import torch and reload your PyTorch model\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkMbuulHaX5Y",
        "outputId": "7b07bc09-fab7-45fc-fbc7-e4ab6a090a78"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dataset_root = \"langData/dataset - Copy\"   # adjust if needed\n",
        "for poet in os.listdir(dataset_root):\n",
        "    print(\"Poet folder:\", poet)\n",
        "    poet_path = os.path.join(dataset_root, poet)\n",
        "    print(\"Contains:\", os.listdir(poet_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dreo-3_4a98O",
        "outputId": "c02413aa-2669-4f30-8101-6f26e7d72855"
      },
      "outputs": [],
      "source": [
        "poet = os.listdir('langData/dataset - Copy')[0]  # first poet folder\n",
        "print(\"UR files:\", os.listdir(os.path.join(dataset_root, poet, \"ur\")))\n",
        "print(\"EN files:\", os.listdir(os.path.join(dataset_root, poet, \"en\")))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0Yi6VGJbUzH",
        "outputId": "a6f4a2c8-4eb3-4b46-dd8c-2f8cd6a2583d"
      },
      "outputs": [],
      "source": [
        "raw_pairs = collect_pairs(dataset_root)\n",
        "print(f\"Total pairs: {len(raw_pairs)}\")\n",
        "print(\"Example:\", raw_pairs[:5])\n",
        "\n",
        "raw_pairs = collect_pairs(dataset_root)\n",
        "print(f\"Total pairs: {len(raw_pairs)}\")\n",
        "print(\"Example:\", raw_pairs[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdFxBIwcYEmP",
        "outputId": "c1730da0-30d9-4cec-e4ab-d0ba5abef945"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Imports (run once)\n",
        "import os\n",
        "import unicodedata\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle  # For saving\n",
        "\n",
        "# Cell 2: Collect pairs\n",
        "def collect_pairs(dataset_root):\n",
        "    pairs = []\n",
        "    for poet in os.listdir(dataset_root):\n",
        "        poet_path = os.path.join(dataset_root, poet)\n",
        "        if not os.path.isdir(poet_path):\n",
        "            continue\n",
        "\n",
        "        ur_path = os.path.join(poet_path, 'ur')\n",
        "        en_path = os.path.join(poet_path, 'en')\n",
        "\n",
        "        if os.path.exists(ur_path) and os.path.exists(en_path):\n",
        "            for filename in os.listdir(ur_path):\n",
        "                ur_file = os.path.join(ur_path, filename)\n",
        "                en_file = os.path.join(en_path, filename)  # same name expected\n",
        "                if os.path.exists(en_file):  # check English file exists\n",
        "                    try:\n",
        "                        with open(ur_file, 'r', encoding='utf-8') as f_ur, \\\n",
        "                             open(en_file, 'r', encoding='utf-8') as f_en:\n",
        "                            ur_lines = f_ur.readlines()\n",
        "                            en_lines = f_en.readlines()\n",
        "                            if len(ur_lines) == len(en_lines):\n",
        "                                for ur_line, en_line in zip(ur_lines, en_lines):\n",
        "                                    if ur_line.strip() and en_line.strip():\n",
        "                                        pairs.append((ur_line.strip(), en_line.strip()))\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error in {filename}: {e}\")\n",
        "    return pairs\n",
        "\n",
        "# Usage: Replace with your path\n",
        "dataset_root = 'langData/dataset - Copy'  # Example\n",
        "raw_pairs = collect_pairs(dataset_root)\n",
        "print(f\"Total pairs: {len(raw_pairs)}\")  # Check ~thousands\n",
        "\n",
        "# Cell 3: Clean text\n",
        "def clean_text(text, is_urdu=True):\n",
        "    text = unicodedata.normalize('NFC', text)  # Normalize Unicode\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Extra spaces\n",
        "    # Keep poetic punct; remove only junk if needed: text = re.sub(r'[^\\w\\s\\u0600-\\u06FF]', '', text) for Urdu range\n",
        "    if not is_urdu:\n",
        "        text = text.lower()  # Lower Roman Urdu\n",
        "    return text\n",
        "\n",
        "cleaned_pairs = [(clean_text(ur, is_urdu=True), clean_text(en, is_urdu=False)) for ur, en in raw_pairs]\n",
        "\n",
        "# Cell 4: Splits\n",
        "train_pairs, val_test_pairs = train_test_split(cleaned_pairs, train_size=0.5, random_state=42)\n",
        "val_pairs, test_pairs = train_test_split(val_test_pairs, test_size=0.5, random_state=42)\n",
        "print(f\"Train: {len(train_pairs)}, Val: {len(val_pairs)}, Test: {len(test_pairs)}\")\n",
        "\n",
        "# Cell 5: BPE from scratch (full impl)\n",
        "class BPE:\n",
        "    def __init__(self, vocab_size=10000):  # Adjust size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.merges = {}\n",
        "        self.vocab = {}\n",
        "\n",
        "    def get_stats(self, byte_arr):\n",
        "        count = defaultdict(int)\n",
        "        for pair in zip(byte_arr[:-1], byte_arr[1:]):\n",
        "            count[pair] += 1\n",
        "        return count\n",
        "\n",
        "    def merge(self, text_bytes, pair, new_byte):\n",
        "        new_bytes = []\n",
        "        i = 0\n",
        "        while i < len(text_bytes):\n",
        "            if i < len(text_bytes) - 1 and text_bytes[i] == pair[0] and text_bytes[i + 1] == pair[1]:\n",
        "                new_bytes.append(new_byte)\n",
        "                i += 2\n",
        "            else:\n",
        "                new_bytes.append(text_bytes[i])\n",
        "                i += 1\n",
        "        return new_bytes\n",
        "\n",
        "    def train(self, corpus):\n",
        "        all_text = ' '.join(corpus)  # Concat for training\n",
        "        text_bytes = list(all_text.encode('utf-8'))  # Byte list\n",
        "        vocab = {i: bytes([i]) for i in range(256)}\n",
        "        num_merges = self.vocab_size - 256\n",
        "        for i in range(num_merges):\n",
        "            stats = self.get_stats(text_bytes)\n",
        "            if not stats:\n",
        "                break\n",
        "            top_pair = max(stats, key=stats.get)\n",
        "            new_idx = 256 + i\n",
        "            text_bytes = self.merge(text_bytes, top_pair, new_idx)\n",
        "            self.merges[top_pair] = new_idx\n",
        "            vocab[new_idx] = vocab[top_pair[0]] + vocab[top_pair[1]]\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def encode(self, text):\n",
        "        text_bytes = list(text.encode('utf-8'))\n",
        "        while len(text_bytes) >= 2:\n",
        "            stats = self.get_stats(text_bytes)\n",
        "            pair = min(stats, key=lambda p: self.merges.get(p, float('inf')))\n",
        "            if pair not in self.merges:\n",
        "                break\n",
        "            new_byte = self.merges[pair]\n",
        "            text_bytes = self.merge(text_bytes, pair, new_byte)\n",
        "        return text_bytes  # Token IDs\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        text = b''.join(self.vocab[t] for t in tokens if t in self.vocab)\n",
        "        return text.decode('utf-8', errors='replace')\n",
        "\n",
        "# Train separate BPE for ur and en (on train only)\n",
        "ur_corpus = [ur for ur, _ in train_pairs]\n",
        "en_corpus = [en for _, en in train_pairs]\n",
        "\n",
        "ur_bpe = BPE(vocab_size=5000)  # Small for low-resource\n",
        "ur_bpe.train(ur_corpus)\n",
        "\n",
        "en_bpe = BPE(vocab_size=5000)\n",
        "en_bpe.train(en_corpus)\n",
        "\n",
        "# Tokenize datasets (add SOS/EOS later in model)\n",
        "def tokenize_pairs(pairs, src_bpe, tgt_bpe):\n",
        "    return [(src_bpe.encode(ur), tgt_bpe.encode(en)) for ur, en in pairs]\n",
        "\n",
        "train_data = tokenize_pairs(train_pairs, ur_bpe, en_bpe)\n",
        "val_data = tokenize_pairs(val_pairs, ur_bpe, en_bpe)\n",
        "test_data = tokenize_pairs(test_pairs, ur_bpe, en_bpe)\n",
        "\n",
        "# Save\n",
        "with open('bpe_models.pkl', 'wb') as f:\n",
        "    pickle.dump((ur_bpe, en_bpe), f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrDGkf-yhKIY"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_dim, hidden_size, num_layers=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size  # per-direction hidden size\n",
        "        self.embedding = nn.Embedding(input_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim, hidden_size, num_layers,\n",
        "            bidirectional=True, dropout=dropout\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src: [seq_len, batch]\n",
        "        embedded = self.dropout(self.embedding(src))      # [seq_len, batch, emb]\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        # hidden / cell: [num_layers * 2, batch, hidden_size] (2 for directions)\n",
        "\n",
        "        # Reshape -> [num_layers, 2, batch, hidden_size]\n",
        "        hidden = hidden.view(self.num_layers, 2, src.size(1), self.hidden_size)\n",
        "        cell   = cell.view(self.num_layers, 2, src.size(1), self.hidden_size)\n",
        "\n",
        "        # Concat forward & backward for each layer -> [num_layers, batch, hidden_size*2]\n",
        "        hidden = torch.cat((hidden[:,0,:,:], hidden[:,1,:,:]), dim=2)\n",
        "        cell   = torch.cat((cell[:,0,:,:],   cell[:,1,:,:]),   dim=2)\n",
        "\n",
        "        # outputs shape remains [seq_len, batch, hidden_size*2] (because bidir output)\n",
        "        return outputs, hidden, cell\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_size, embedding_dim, hidden_size, num_layers=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        # hidden_size here = per-direction encoder hidden_size; decoder's RNN hidden will be hidden_size*2\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(output_size, embedding_dim, padding_idx=0)\n",
        "        self.rnn_hidden = hidden_size * 2\n",
        "        self.lstm = nn.LSTM(embedding_dim, self.rnn_hidden, num_layers, dropout=dropout)\n",
        "        self.fc = nn.Linear(self.rnn_hidden, output_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, tgt_token, hidden, cell):\n",
        "        # tgt_token: [batch] (one timestep)\n",
        "        tgt = tgt_token.unsqueeze(0)                    # [1, batch]\n",
        "        embedded = self.dropout(self.embedding(tgt))   # [1, batch, emb]\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        prediction = self.fc(output.squeeze(0))        # [batch, output_size]\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder: Encoder, decoder: Decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "        self.enc_layers = encoder.num_layers\n",
        "        self.dec_layers = decoder.num_layers\n",
        "\n",
        "        # Create bridge (map last-dim from enc_hidden*2 -> decoder.rnn_hidden)\n",
        "        in_feats = encoder.hidden_size * 2\n",
        "        out_feats = decoder.rnn_hidden\n",
        "        if self.enc_layers != self.dec_layers or in_feats != out_feats:\n",
        "            self.hidden_bridge = nn.Linear(in_feats, out_feats)\n",
        "            self.cell_bridge = nn.Linear(in_feats, out_feats)\n",
        "        else:\n",
        "            self.hidden_bridge = None\n",
        "            self.cell_bridge = None\n",
        "\n",
        "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
        "        # src: [src_len, batch], tgt: [tgt_len, batch]\n",
        "        batch_size = tgt.shape[1]\n",
        "        tgt_len = tgt.shape[0]\n",
        "        tgt_vocab_size = self.decoder.fc.out_features\n",
        "        outputs = torch.zeros(tgt_len, batch_size, tgt_vocab_size, device=src.device)\n",
        "\n",
        "        # Encoder\n",
        "        _, hidden, cell = self.encoder(src)\n",
        "        # hidden & cell: [enc_layers, batch, enc_hidden*2]\n",
        "\n",
        "        # Bridge (map last dimension) if needed\n",
        "        if self.hidden_bridge is not None:\n",
        "            hidden = self.hidden_bridge(hidden)  # applies to last dim -> [enc_layers, batch, dec_hidden]\n",
        "            cell = self.cell_bridge(cell)\n",
        "\n",
        "        # Expand (repeat) along layer dimension only ONCE to match decoder.num_layers\n",
        "        if self.enc_layers != self.dec_layers:\n",
        "            repeats = math.ceil(self.dec_layers / self.enc_layers)\n",
        "            hidden = hidden.repeat(repeats, 1, 1)[:self.dec_layers, :, :]  # [dec_layers, batch, dec_hidden]\n",
        "            cell = cell.repeat(repeats, 1, 1)[:self.dec_layers, :, :]\n",
        "\n",
        "        # Decoder loop\n",
        "        input = tgt[0, :]  # SOS tokens\n",
        "        for t in range(1, tgt_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            outputs[t] = output\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input = tgt[t] if teacher_force else top1\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cae7RrLlgqj"
      },
      "source": [
        "# New Section\n",
        "Sanity Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmwewpsTlnky",
        "outputId": "5506681f-b383-469c-9bd3-dcfd314a1eef"
      },
      "outputs": [],
      "source": [
        "# small shape check (no gradients needed)\n",
        "input_size = len(ur_bpe.vocab)\n",
        "output_size = len(en_bpe.vocab)\n",
        "enc = Encoder(input_size, embedding_dim=32, hidden_size=64, num_layers=2)\n",
        "dec = Decoder(output_size, embedding_dim=32, hidden_size=64, num_layers=4)\n",
        "model = Seq2Seq(enc, dec)\n",
        "src = torch.randint(0, input_size, (10, 8))   # [src_len, batch=8]\n",
        "tgt = torch.randint(0, output_size, (12, 8))  # [tgt_len, batch=8]\n",
        "out = model(src, tgt)                         # should run without hidden-size errors\n",
        "print(\"out.shape:\", out.shape)  # (tgt_len, batch, vocab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT9L6Z3zhdHo",
        "outputId": "3c5b2e10-4f07-4fad-fa68-76a349a7cbd9"
      },
      "outputs": [],
      "source": [
        "# Cell: Data preparation\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.data[idx][0]), torch.tensor(self.data[idx][1])  # src, tgt tokens\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_batch = pad_sequence(src_batch, padding_value=0, batch_first=False)  # [seq, batch]\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=0, batch_first=False)\n",
        "    return src_batch, tgt_batch\n",
        "\n",
        "# Loaders (adjust batch_size later)\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(TranslationDataset(train_data), batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(TranslationDataset(val_data), batch_size=batch_size, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(TranslationDataset(test_data), batch_size=batch_size, collate_fn=collate_fn)\n",
        "\n",
        "# Cell: Training\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hypers (vary in experiments)\n",
        "input_size = len(ur_bpe.vocab)  # Src vocab\n",
        "output_size = len(en_bpe.vocab)  # Tgt vocab\n",
        "embedding_dim = 256\n",
        "hidden_size = 512\n",
        "encoder_layers = 2\n",
        "decoder_layers = 4\n",
        "dropout = 0.1\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 20  # Adjust\n",
        "\n",
        "encoder = Encoder(input_size, embedding_dim, hidden_size, encoder_layers, dropout)\n",
        "decoder = Decoder(output_size, embedding_dim, hidden_size, decoder_layers, dropout)\n",
        "model = Seq2Seq(encoder, decoder).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Pad=0\n",
        "\n",
        "def train(model, loader, optimizer, criterion, clip=1):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for src, tgt in loader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        tgt = tgt[1:].view(-1)\n",
        "        loss = criterion(output, tgt)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in loader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            output = model(src, tgt, 0)  # No teacher forcing\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            tgt = tgt[1:].view(-1)\n",
        "            loss = criterion(output, tgt)\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(loader)\n",
        "\n",
        "# Train loop\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion)\n",
        "    val_loss = evaluate(model, val_loader, criterion)\n",
        "    print(f'Epoch {epoch}: Train Loss {train_loss:.3f}, Val Loss {val_loss:.3f}')\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), 'model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibPmnCW2rdj_",
        "outputId": "3c45e8b8-b965-4f02-d788-fef7c0a9792a"
      },
      "outputs": [],
      "source": [
        "# Cell: Metrics + Experiments\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import math\n",
        "from jiwer import cer, wer  # CER and WER\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def calculate_metrics(model, loader, tgt_bpe):\n",
        "    model.eval()\n",
        "    refs, hyps = [], []\n",
        "    perplexities, cers, wers = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in loader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            output = model(src, tgt, 0)\n",
        "            for i in range(src.shape[1]):\n",
        "                pred = output[:, i, :].argmax(1).cpu().tolist()\n",
        "                ref = tgt[1:, i].cpu().tolist()\n",
        "\n",
        "                hyp_text = tgt_bpe.decode(pred)\n",
        "                ref_text = tgt_bpe.decode(ref)\n",
        "\n",
        "                refs.append([ref_text.split()])\n",
        "                hyps.append(hyp_text.split())\n",
        "\n",
        "                # Perplexity\n",
        "                loss = criterion(output[1:, i, :], tgt[1:, i])\n",
        "                perplexities.append(math.exp(loss.item()))\n",
        "\n",
        "                # CER / WER\n",
        "                cers.append(cer(ref_text, hyp_text))\n",
        "                wers.append(wer(ref_text, hyp_text))\n",
        "\n",
        "    bleu = sum(sentence_bleu(r, h, smoothing_function=SmoothingFunction().method1) for r, h in zip(refs, hyps)) / len(refs)\n",
        "    avg_perp = sum(perplexities) / len(perplexities)\n",
        "    avg_cer = sum(cers) / len(cers)\n",
        "    avg_wer = sum(wers) / len(wers)\n",
        "\n",
        "    return {\"BLEU\": bleu, \"Perplexity\": avg_perp, \"CER\": avg_cer, \"WER\": avg_wer}\n",
        "\n",
        "\n",
        "def run_experiment(embedding_dim, hidden_size, encoder_layers=2, decoder_layers=4,\n",
        "                   dropout=0.1, lr=1e-3, batch_size=32, exp_name=\"\"):\n",
        "    # Re-create loaders\n",
        "    global train_loader, val_loader, test_loader\n",
        "    train_loader = DataLoader(TranslationDataset(train_data), batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(TranslationDataset(val_data), batch_size=batch_size, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(TranslationDataset(test_data), batch_size=batch_size, collate_fn=collate_fn)\n",
        "\n",
        "    # Build model\n",
        "    encoder = Encoder(input_size, embedding_dim, hidden_size, encoder_layers, dropout).to(device)\n",
        "    decoder = Decoder(output_size, embedding_dim, hidden_size, decoder_layers, dropout).to(device)\n",
        "    model = Seq2Seq(encoder, decoder).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Train\n",
        "    history = {\"train_loss\": [], \"val_loss\": []}\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train(model, train_loader, optimizer, criterion)\n",
        "        val_loss = evaluate(model, val_loader, criterion)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        print(f\"[{exp_name}] Epoch {epoch}: Train {train_loss:.3f}, Val {val_loss:.3f}\")\n",
        "\n",
        "    # Final eval\n",
        "    test_loss = evaluate(model, test_loader, criterion)\n",
        "    metrics = calculate_metrics(model, test_loader, en_bpe)\n",
        "    metrics[\"Test Loss\"] = test_loss\n",
        "    return metrics, history\n",
        "\n",
        "\n",
        "def run_all_experiments():\n",
        "    experiments = [\n",
        "        {\"name\": \"Small baseline\", \"embedding_dim\":128, \"hidden_size\":256, \"encoder_layers\":1, \"decoder_layers\":2, \"dropout\":0.1, \"lr\":1e-3, \"batch_size\":32},\n",
        "        {\"name\": \"Medium balanced\", \"embedding_dim\":256, \"hidden_size\":512, \"encoder_layers\":2, \"decoder_layers\":3, \"dropout\":0.3, \"lr\":5e-4, \"batch_size\":64},\n",
        "        {\"name\": \"Large model\", \"embedding_dim\":512, \"hidden_size\":512, \"encoder_layers\":4, \"decoder_layers\":4, \"dropout\":0.3, \"lr\":5e-4, \"batch_size\":64},\n",
        "        {\"name\": \"High dropout\", \"embedding_dim\":256, \"hidden_size\":256, \"encoder_layers\":2, \"decoder_layers\":2, \"dropout\":0.5, \"lr\":1e-3, \"batch_size\":32},\n",
        "        {\"name\": \"Stable slow\", \"embedding_dim\":256, \"hidden_size\":512, \"encoder_layers\":3, \"decoder_layers\":4, \"dropout\":0.3, \"lr\":1e-4, \"batch_size\":128},\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "    for i, config in enumerate(experiments, 1):\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(f\"Running Experiment {i}/{len(experiments)}: {config['name']}\")\n",
        "        print(config)\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        start_time = time.time()\n",
        "        metrics, history = run_experiment(\n",
        "            embedding_dim=config[\"embedding_dim\"],\n",
        "            hidden_size=config[\"hidden_size\"],\n",
        "            encoder_layers=config[\"encoder_layers\"],\n",
        "            decoder_layers=config[\"decoder_layers\"],\n",
        "            dropout=config[\"dropout\"],\n",
        "            lr=config[\"lr\"],\n",
        "            batch_size=config[\"batch_size\"],\n",
        "            exp_name=config[\"name\"]\n",
        "        )\n",
        "        elapsed = time.time() - start_time\n",
        "        metrics[\"Name\"] = config[\"name\"]\n",
        "        metrics[\"Time (s)\"] = elapsed\n",
        "        results.append(metrics)\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    print(\"\\n=== Final Results ===\")\n",
        "    print(df)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt4PJetWtZlT",
        "outputId": "e3d39261-bbaf-4185-f9e2-f3e8ec243e6c"
      },
      "outputs": [],
      "source": [
        "df_results = run_all_experiments()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
