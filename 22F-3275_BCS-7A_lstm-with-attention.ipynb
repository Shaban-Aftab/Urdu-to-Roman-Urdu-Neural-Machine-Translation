{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urdu to Roman Urdu Neural Machine Translation With LSTM \n",
    "\n",
    "This notebook contains:\n",
    "1. Data preprocessing and tokenization\n",
    "2. BiLSTM Encoder-Decoder model with attention\n",
    "3. Fixed training loop with proper evaluation\n",
    "4. Corrected BLEU score calculation\n",
    "5. Perplexity and CER evaluation metrics\n",
    "6. Training function with multiple metrics\n",
    "7. Improved inference function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T04:11:03.856266Z",
     "iopub.status.busy": "2025-09-25T04:11:03.855550Z",
     "iopub.status.idle": "2025-09-25T04:11:08.633691Z",
     "shell.execute_reply": "2025-09-25T04:11:08.632912Z",
     "shell.execute_reply.started": "2025-09-25T04:11:03.856219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Install required packages\n",
    "# !pip install sentencepiece\n",
    "\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T04:23:37.037387Z",
     "iopub.status.busy": "2025-09-25T04:23:37.036641Z",
     "iopub.status.idle": "2025-09-25T04:23:37.122192Z",
     "shell.execute_reply": "2025-09-25T04:23:37.121578Z",
     "shell.execute_reply.started": "2025-09-25T04:23:37.037346Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set random seeds\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T19:26:32.228330Z",
     "iopub.status.busy": "2025-09-24T19:26:32.228080Z",
     "iopub.status.idle": "2025-09-24T19:26:32.235748Z",
     "shell.execute_reply": "2025-09-24T19:26:32.234986Z",
     "shell.execute_reply.started": "2025-09-24T19:26:32.228311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===================== TOKENIZATION =====================\n",
    "\n",
    "def create_tokenizers(train_urdu, train_roman, vocab_size=4000):\n",
    "\n",
    "    \n",
    "    print(f\"Training SentencePiece tokenizers with vocab_size={vocab_size}...\")\n",
    "    \n",
    "    # Create tokenizers directory\n",
    "    os.makedirs('tokenizers', exist_ok=True)\n",
    "    \n",
    "    # Save training data\n",
    "    with open('tokenizers/urdu_train.txt', 'w', encoding='utf-8') as f:\n",
    "        for text in train_urdu:\n",
    "            f.write(text + '\\n')\n",
    "    \n",
    "    with open('tokenizers/roman_train.txt', 'w', encoding='utf-8') as f:\n",
    "        for text in train_roman:\n",
    "            f.write(text + '\\n')\n",
    "    \n",
    "    # Estimate reasonable vocab size based on data\n",
    "    def estimate_vocab_size(texts, target_size):\n",
    "        \n",
    "        all_text = ' '.join(texts)\n",
    "        unique_chars = len(set(all_text))\n",
    "        unique_words = len(set(all_text.split()))\n",
    "        # Use target size but cap at reasonable limits\n",
    "        return min(target_size, max(unique_chars * 10, 1000), unique_words)\n",
    "    \n",
    "    urdu_vocab_size = estimate_vocab_size(train_urdu, vocab_size)\n",
    "    roman_vocab_size = estimate_vocab_size(train_roman, vocab_size)\n",
    "    \n",
    "    print(f\"Adjusted vocab sizes - Urdu: {urdu_vocab_size}, Roman: {roman_vocab_size}\")\n",
    "    \n",
    "    # Train Urdu tokenizer\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        \n",
    "        input='tokenizers/urdu_train.txt',\n",
    "        model_prefix='tokenizers/urdu_tokenizer',\n",
    "        vocab_size=urdu_vocab_size,\n",
    "        model_type='unigram',\n",
    "        character_coverage=1.0,\n",
    "        pad_id=0, unk_id=1, bos_id=2, eos_id=3\n",
    "    )\n",
    "    \n",
    "    # Train Roman tokenizer\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input='tokenizers/roman_train.txt',\n",
    "        model_prefix='tokenizers/roman_tokenizer',\n",
    "        vocab_size=roman_vocab_size,\n",
    "        model_type='unigram',\n",
    "        character_coverage=1.0,\n",
    "        pad_id=0, unk_id=1, bos_id=2, eos_id=3\n",
    "    )\n",
    "    \n",
    "    # Load trained models\n",
    "    urdu_tokenizer = spm.SentencePieceProcessor(model_file='tokenizers/urdu_tokenizer.model')\n",
    "    roman_tokenizer = spm.SentencePieceProcessor(model_file='tokenizers/roman_tokenizer.model')\n",
    "    \n",
    "    print(f\"Final vocab sizes - Urdu: {urdu_tokenizer.get_piece_size()}, \"\n",
    "          f\"Roman: {roman_tokenizer.get_piece_size()}\")\n",
    "    \n",
    "    return urdu_tokenizer, roman_tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T19:26:32.237980Z",
     "iopub.status.busy": "2025-09-24T19:26:32.237464Z",
     "iopub.status.idle": "2025-09-24T19:26:32.259009Z",
     "shell.execute_reply": "2025-09-24T19:26:32.258385Z",
     "shell.execute_reply.started": "2025-09-24T19:26:32.237962Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===================== DATA PREPROCESSING =====================\n",
    "\n",
    "class UrduRomanDataProcessor:\n",
    "    \n",
    "    def __init__(self, dataset_path: str):\n",
    "        \n",
    "        self.dataset_path = Path(dataset_path)\n",
    "        self.urdu_texts = []\n",
    "        self.roman_texts = []\n",
    "    \n",
    "    def load_data(self):\n",
    "        \n",
    "        print(\"Loading data from urdu_ghazals_rekhta dataset...\")\n",
    "        \n",
    "        if not self.dataset_path.exists():\n",
    "            \n",
    "            raise FileNotFoundError(f\"Dataset path {self.dataset_path} not found\")\n",
    "        \n",
    "        for poet_dir in self.dataset_path.iterdir():\n",
    "            if not poet_dir.is_dir() or poet_dir.name.startswith('.'):\n",
    "                continue\n",
    "                \n",
    "            urdu_dir = poet_dir / 'ur'\n",
    "            english_dir = poet_dir / 'en'  # This contains Roman Urdu transliteration\n",
    "            \n",
    "            if not (urdu_dir.exists() and english_dir.exists()):\n",
    "                continue\n",
    "            \n",
    "            # Get all Urdu files \n",
    "            urdu_files = [f for f in urdu_dir.iterdir() if f.is_file() and not f.name.startswith('.')]\n",
    "            \n",
    "            for urdu_file in urdu_files:\n",
    "                english_file = english_dir / urdu_file.name\n",
    "                \n",
    "                if english_file.exists() and english_file.is_file():\n",
    "                    try:\n",
    "                        # Read Urdu text\n",
    "                        with open(urdu_file, 'r', encoding='utf-8') as f:\n",
    "                            urdu_content = f.read().strip()\n",
    "                        \n",
    "                        # Read Roman Urdu text\n",
    "                        with open(english_file, 'r', encoding='utf-8') as f:\n",
    "                            roman_content = f.read().strip()\n",
    "                        \n",
    "                        # Split by lines to get verse pairs\n",
    "                        urdu_lines = [line.strip() for line in urdu_content.split('\\n') if line.strip()]\n",
    "                        roman_lines = [line.strip() for line in roman_content.split('\\n') if line.strip()]\n",
    "                        \n",
    "                        # Pair up lines (verses)\n",
    "                        for urdu_line, roman_line in zip(urdu_lines, roman_lines):\n",
    "                            if urdu_line and roman_line:\n",
    "                                self.urdu_texts.append(urdu_line)\n",
    "                                self.roman_texts.append(roman_line)\n",
    "                                \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {urdu_file.name}: {e}\")\n",
    "                        continue\n",
    "        \n",
    "        print(f\"Loaded {len(self.urdu_texts)} text pairs\")\n",
    "        \n",
    "        if len(self.urdu_texts) == 0:\n",
    "            raise ValueError(\"No data loaded. Check dataset structure and paths.\")\n",
    "    \n",
    "    def clean_text(self, text: str, is_urdu: bool = True) -> str:\n",
    "        \n",
    "        \"\"\"Clean and normalize text\"\"\"\n",
    "        # Unicode normalization\n",
    "        text = unicodedata.normalize('NFKC', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        if is_urdu:\n",
    "            \n",
    "            # Keep Urdu characters and basic punctuation\n",
    "            text = re.sub(r'[^\\u0600-\\u06FF\\u0750-\\u077F\\s\\.\\,\\?\\!\\:\\;\\-\\(\\)\\\"\\']+', '', text)\n",
    "        else:\n",
    "            \n",
    "            # Convert to lowercase and keep Roman characters\n",
    "            text = text.lower()\n",
    "            text = re.sub(r'[^a-z0-9\\s\\.\\,\\?\\!\\:\\;\\-\\(\\)\\\"\\']+', '', text)\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def preprocess_data(self, min_words=3, max_words=50):\n",
    "        \n",
    "        \"\"\"Clean and filter the data\"\"\"\n",
    "        print(\"Preprocessing and filtering data...\")\n",
    "        \n",
    "        cleaned_urdu = []\n",
    "        cleaned_roman = []\n",
    "        \n",
    "        for urdu, roman in zip(self.urdu_texts, self.roman_texts):\n",
    "            # Clean texts\n",
    "            clean_urdu = self.clean_text(urdu, is_urdu=True)\n",
    "            clean_roman = self.clean_text(roman, is_urdu=False)\n",
    "            \n",
    "            # Filter by length\n",
    "            urdu_words = len(clean_urdu.split())\n",
    "            roman_words = len(clean_roman.split())\n",
    "            \n",
    "            if (min_words <= urdu_words <= max_words and \n",
    "                min_words <= roman_words <= max_words and \n",
    "                clean_urdu and clean_roman):\n",
    "                cleaned_urdu.append(clean_urdu)\n",
    "                cleaned_roman.append(clean_roman)\n",
    "        \n",
    "        self.urdu_texts = cleaned_urdu\n",
    "        self.roman_texts = cleaned_roman\n",
    "        \n",
    "        print(f\"After preprocessing: {len(self.urdu_texts)} pairs\")\n",
    "        \n",
    "        if len(self.urdu_texts) < 100:\n",
    "            print(\"Warning: Very few text pairs available. Consider relaxing filtering criteria.\")\n",
    "    \n",
    "    def split_data(self, test_size=0.25, val_size=0.25, random_state=42):\n",
    "        \"\"\"Split data into train/val/test sets (50/25/25 as required)\"\"\"\n",
    "        # First split: separate test set (25%)\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            self.urdu_texts, self.roman_texts, \n",
    "            test_size=test_size, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Second split: divide remaining into train/val\n",
    "        val_adjusted = val_size / (1 - test_size)  # 0.25 / 0.75 = 0.333\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_temp, y_temp, \n",
    "            test_size=val_adjusted, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        print(f\"Data split - Train: {len(X_train)} ({len(X_train)/len(self.urdu_texts)*100:.1f}%), \"\n",
    "              f\"Val: {len(X_val)} ({len(X_val)/len(self.urdu_texts)*100:.1f}%), \"\n",
    "              f\"Test: {len(X_test)} ({len(X_test)/len(self.urdu_texts)*100:.1f}%)\")\n",
    "        \n",
    "        return {\n",
    "            'train': {'urdu': X_train, 'roman': y_train},\n",
    "            'val': {'urdu': X_val, 'roman': y_val},\n",
    "            'test': {'urdu': X_test, 'roman': y_test}\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PyTorch Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T19:26:32.259922Z",
     "iopub.status.busy": "2025-09-24T19:26:32.259741Z",
     "iopub.status.idle": "2025-09-24T19:26:32.311024Z",
     "shell.execute_reply": "2025-09-24T19:26:32.310304Z",
     "shell.execute_reply.started": "2025-09-24T19:26:32.259907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===================== DATASET AND DATALOADER =====================\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    \n",
    "    \"\"\"Dataset for translation pairs\"\"\"\n",
    "    \n",
    "    def __init__(self, urdu_texts, roman_texts, urdu_tokenizer, roman_tokenizer, max_length=50):\n",
    "        \n",
    "        self.urdu_texts = urdu_texts\n",
    "        self.roman_texts = roman_texts\n",
    "        self.urdu_tokenizer = urdu_tokenizer\n",
    "        self.roman_tokenizer = roman_tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.urdu_texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        urdu_text = self.urdu_texts[idx]\n",
    "        roman_text = self.roman_texts[idx]\n",
    "        \n",
    "        # Tokenize\n",
    "        urdu_tokens = self.urdu_tokenizer.encode(urdu_text, out_type=int)\n",
    "        roman_tokens = self.roman_tokenizer.encode(roman_text, out_type=int)\n",
    "        \n",
    "        # Ensure BOS and EOS in target and respect max_length\n",
    "        roman_tokens = roman_tokens[:max(0, self.max_length - 2)]\n",
    "        roman_tokens = [2] + roman_tokens + [3]\n",
    "        \n",
    "        # Truncate if necessary\n",
    "        urdu_tokens = urdu_tokens[:self.max_length]\n",
    "        \n",
    "        return {\n",
    "            'urdu': torch.tensor(urdu_tokens, dtype=torch.long),\n",
    "            'roman': torch.tensor(roman_tokens, dtype=torch.long),\n",
    "            'urdu_text': urdu_text,\n",
    "            'roman_text': roman_text\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \n",
    "    \"\"\"Collate function with padding\"\"\"\n",
    "    urdu_seqs = [item['urdu'] for item in batch]\n",
    "    roman_seqs = [item['roman'] for item in batch]\n",
    "    \n",
    "    # Pad sequences\n",
    "    urdu_padded = nn.utils.rnn.pad_sequence(urdu_seqs, batch_first=True, padding_value=0)\n",
    "    roman_padded = nn.utils.rnn.pad_sequence(roman_seqs, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return {\n",
    "        \n",
    "        'urdu': urdu_padded,\n",
    "        'roman': roman_padded,\n",
    "        'urdu_texts': [item['urdu_text'] for item in batch],\n",
    "        'roman_texts': [item['roman_text'] for item in batch]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BiLSTM Encoder (2 layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T19:26:32.312526Z",
     "iopub.status.busy": "2025-09-24T19:26:32.312013Z",
     "iopub.status.idle": "2025-09-24T19:26:32.327720Z",
     "shell.execute_reply": "2025-09-24T19:26:32.327064Z",
     "shell.execute_reply.started": "2025-09-24T19:26:32.312499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===================== MODEL ARCHITECTURE =====================\n",
    "\n",
    "class BiLSTMEncoder(nn.Module):\n",
    "    \n",
    "    \"\"\"BiLSTM Encoder (2 layers as required)\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2, dropout=0.1):\n",
    "        \n",
    "        super(BiLSTMEncoder, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embed_dim, hidden_dim, num_layers, \n",
    "            batch_first=True, bidirectional=True, dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, lengths=None):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Embedding\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        \n",
    "        # Pack padded sequence for efficiency if lengths provided\n",
    "        \n",
    "        if lengths is not None:\n",
    "            packed = nn.utils.rnn.pack_padded_sequence(\n",
    "                embedded, lengths, batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            outputs, (hidden, cell) = self.lstm(packed)\n",
    "            outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "        else:\n",
    "            outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        \n",
    "        return outputs, hidden, cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T19:26:32.328609Z",
     "iopub.status.busy": "2025-09-24T19:26:32.328346Z",
     "iopub.status.idle": "2025-09-24T19:26:32.346305Z",
     "shell.execute_reply": "2025-09-24T19:26:32.345690Z",
     "shell.execute_reply.started": "2025-09-24T19:26:32.328571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"Attention mechanism with masking support\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.attn = nn.Linear(hidden_dim * 3, hidden_dim)\n",
    "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs, mask=None):\n",
    "        # hidden: (batch_size, hidden_dim)\n",
    "        # encoder_outputs: (batch_size, seq_len, hidden_dim*2)\n",
    "        # mask: (batch_size, seq_len) - 1 for valid positions, 0 for padding\n",
    "        \n",
    "        batch_size, seq_len, _ = encoder_outputs.size()\n",
    "        \n",
    "        # Repeat hidden for all encoder positions\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        \n",
    "        # Compute attention energies\n",
    "        energy = torch.cat([hidden, encoder_outputs], dim=2)\n",
    "        energy = torch.tanh(self.attn(energy))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        # Apply mask if provided\n",
    "        if mask is not None:\n",
    "            attention = attention.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        # Compute attention weights\n",
    "        attention_weights = F.softmax(attention, dim=1)\n",
    "        \n",
    "        # Apply attention to encoder outputs\n",
    "        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs)\n",
    "        context = context.squeeze(1)\n",
    "        \n",
    "        return context, attention_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LSTM Decoder with Attention (4 layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T19:26:32.347282Z",
     "iopub.status.busy": "2025-09-24T19:26:32.347052Z",
     "iopub.status.idle": "2025-09-24T19:26:32.365372Z",
     "shell.execute_reply": "2025-09-24T19:26:32.364752Z",
     "shell.execute_reply.started": "2025-09-24T19:26:32.347266Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class LSTMDecoder(nn.Module):\n",
    "    \"\"\"LSTM Decoder with attention (4 layers as required)\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=4, dropout=0.1):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            embed_dim + hidden_dim * 2, hidden_dim, num_layers,\n",
    "            batch_first=True, dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.output_projection = nn.Linear(hidden_dim + hidden_dim * 2, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, hidden_state, encoder_outputs, encoder_mask=None):\n",
    "        # x: (batch_size, 1) - single time step\n",
    "        # Ensure x has correct shape\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(1)\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        \n",
    "        # Get context from attention\n",
    "        context, attention_weights = self.attention(\n",
    "            hidden_state[0][-1], encoder_outputs, encoder_mask\n",
    "        )\n",
    "        \n",
    "        # Concatenate embedding with context\n",
    "        lstm_input = torch.cat([embedded, context.unsqueeze(1)], dim=2)\n",
    "        \n",
    "        # LSTM forward\n",
    "        output, hidden_state = self.lstm(lstm_input, hidden_state)\n",
    "        \n",
    "        # Final output projection\n",
    "        final_output = torch.cat([output, context.unsqueeze(1)], dim=2)\n",
    "        predictions = self.output_projection(final_output)\n",
    "        \n",
    "        return predictions, hidden_state, attention_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Complete Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T19:26:32.366503Z",
     "iopub.status.busy": "2025-09-24T19:26:32.366239Z",
     "iopub.status.idle": "2025-09-24T19:26:32.388371Z",
     "shell.execute_reply": "2025-09-24T19:26:32.387692Z",
     "shell.execute_reply.started": "2025-09-24T19:26:32.366461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    \n",
    "    \"\"\"Seq2Seq model with BiLSTM encoder and LSTM decoder\"\"\"\n",
    "    \n",
    "    def __init__(self, urdu_vocab_size, roman_vocab_size, embed_dim=128, hidden_dim=256,\n",
    "                 encoder_layers=2, decoder_layers=4, dropout=0.1):\n",
    "        \n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "        \n",
    "        self.encoder = BiLSTMEncoder(urdu_vocab_size, embed_dim, hidden_dim, encoder_layers, dropout)\n",
    "        self.decoder = LSTMDecoder(roman_vocab_size, embed_dim, hidden_dim, decoder_layers, dropout)\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.encoder_layers = encoder_layers\n",
    "        self.decoder_layers = decoder_layers\n",
    "        \n",
    "        # Bridge to convert bidirectional encoder hidden to decoder hidden\n",
    "        self.bridge_h = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.bridge_c = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "    \n",
    "    def forward(self, urdu_seq, roman_seq=None, teacher_forcing_ratio=0.5):\n",
    "        \n",
    "        batch_size = urdu_seq.size(0)\n",
    "        device = urdu_seq.device\n",
    "        \n",
    "        # Create encoder mask\n",
    "        encoder_mask = (urdu_seq != 0).float()\n",
    "        encoder_lengths = encoder_mask.sum(dim=1).cpu()\n",
    "        \n",
    "        # Encode\n",
    "        encoder_outputs, encoder_hidden, encoder_cell = self.encoder(urdu_seq, encoder_lengths)\n",
    "        \n",
    "        # Convert bidirectional encoder states to decoder states\n",
    "        encoder_hidden = encoder_hidden.view(self.encoder_layers, 2, batch_size, self.hidden_dim)\n",
    "        encoder_cell = encoder_cell.view(self.encoder_layers, 2, batch_size, self.hidden_dim)\n",
    "        \n",
    "        # Concatenate forward and backward states\n",
    "        last_hidden = torch.cat([encoder_hidden[-1, 0], encoder_hidden[-1, 1]], dim=1)\n",
    "        last_cell = torch.cat([encoder_cell[-1, 0], encoder_cell[-1, 1]], dim=1)\n",
    "        \n",
    "        # Bridge to decoder dimensions\n",
    "        decoder_hidden = self.bridge_h(last_hidden).unsqueeze(0).repeat(self.decoder_layers, 1, 1)\n",
    "        decoder_cell = self.bridge_c(last_cell).unsqueeze(0).repeat(self.decoder_layers, 1, 1)\n",
    "        \n",
    "        if roman_seq is not None:  # Training mode\n",
    "            \n",
    "            max_length = roman_seq.size(1)\n",
    "            outputs = []\n",
    "            input_token = roman_seq[:, 0:1]  # SOS token\n",
    "            hidden_state = (decoder_hidden, decoder_cell)\n",
    "            \n",
    "            for t in range(max_length - 1):\n",
    "                \n",
    "                output, hidden_state, _ = self.decoder(\n",
    "                    input_token, hidden_state, encoder_outputs, encoder_mask\n",
    "                )\n",
    "                outputs.append(output)\n",
    "                \n",
    "                # Teacher forcing\n",
    "                if random.random() < teacher_forcing_ratio:\n",
    "                    \n",
    "                    input_token = roman_seq[:, t+1:t+2]\n",
    "                else:\n",
    "                    \n",
    "                    input_token = output.argmax(dim=-1)\n",
    "            \n",
    "            return torch.cat(outputs, dim=1)\n",
    "        \n",
    "        else:  # Inference mode with beam search\n",
    "            \n",
    "            return self.beam_search_decode(\n",
    "                encoder_outputs, encoder_mask, decoder_hidden, decoder_cell, \n",
    "                beam_size=3, max_length=50\n",
    "            )\n",
    "    \n",
    "    def beam_search_decode(self, encoder_outputs, encoder_mask, decoder_hidden, \n",
    "                          decoder_cell, beam_size=3, max_length=50):\n",
    "        \n",
    "        \"\"\"Beam search decoding to avoid repetition\"\"\"\n",
    "        \n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        device = encoder_outputs.device\n",
    "        \n",
    "        # For simplicity, handle batch_size=1 (extend for batches if needed)\n",
    "        if batch_size > 1:\n",
    "            \n",
    "            # Fall back to greedy for batch processing\n",
    "            return self.greedy_decode(encoder_outputs, encoder_mask, decoder_hidden, \n",
    "                                    decoder_cell, max_length)\n",
    "        \n",
    "        # Initialize beams\n",
    "        beams = [([], 0.0, (decoder_hidden, decoder_cell))]  # (sequence, score, hidden_state)\n",
    "        completed = []\n",
    "        \n",
    "        # Start token\n",
    "        start_token = torch.tensor([[2]], dtype=torch.long, device=device)  # SOS\n",
    "        \n",
    "        for step in range(max_length):\n",
    "            \n",
    "            candidates = []\n",
    "            \n",
    "            for seq, score, hidden_state in beams:\n",
    "                \n",
    "                if len(seq) > 0 and seq[-1] == 3:  # EOS token\n",
    "                    completed.append((seq, score))\n",
    "                    continue\n",
    "                \n",
    "                # Get input token\n",
    "                if len(seq) == 0:\n",
    "                    \n",
    "                    input_token = start_token\n",
    "                else:\n",
    "                    \n",
    "                    input_token = torch.tensor([[seq[-1]]], dtype=torch.long, device=device)\n",
    "                \n",
    "                # Decode one step\n",
    "                output, new_hidden, _ = self.decoder(\n",
    "                    input_token, hidden_state, encoder_outputs, encoder_mask\n",
    "                )\n",
    "                \n",
    "                # Get top k tokens\n",
    "                log_probs = F.log_softmax(output.squeeze(1), dim=-1)\n",
    "                top_k_scores, top_k_tokens = log_probs.topk(beam_size)\n",
    "                \n",
    "                for k in range(beam_size):\n",
    "                    \n",
    "                    token = top_k_tokens[0, k].item()\n",
    "                    token_score = top_k_scores[0, k].item()\n",
    "                    \n",
    "                    # Apply repetition penalty\n",
    "                    if len(seq) > 0 and token == seq[-1]:\n",
    "                        \n",
    "                        token_score -= 2.0  # Penalty for immediate repetition\n",
    "                    \n",
    "                    # Check for pattern repetition\n",
    "                    if len(seq) > 3:\n",
    "                        \n",
    "                        recent = seq[-3:]\n",
    "                        if recent.count(token) > 1:\n",
    "                            \n",
    "                            token_score -= 3.0  # Higher penalty for patterns\n",
    "                    \n",
    "                    new_seq = seq + [token]\n",
    "                    new_score = score + token_score\n",
    "                    \n",
    "                    candidates.append((new_seq, new_score, new_hidden))\n",
    "            \n",
    "            # Select top beams\n",
    "            candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "            beams = candidates[:beam_size]\n",
    "            \n",
    "            # Early stopping if all beams are completed\n",
    "            if len(beams) == 0:\n",
    "                break\n",
    "        \n",
    "        # Add remaining beams to completed\n",
    "        completed.extend(beams)\n",
    "        \n",
    "        # Select best sequence\n",
    "        if completed:\n",
    "            best_seq = max(completed, key=lambda x: x[1] / len(x[0]))[0]  # Length normalization\n",
    "        else:\n",
    "            best_seq = beams[0][0] if beams else []\n",
    "        \n",
    "        # Convert to tensor\n",
    "        if best_seq:\n",
    "            \n",
    "            output_tensor = torch.tensor([best_seq], dtype=torch.long, device=device)\n",
    "        else:\n",
    "            output_tensor = torch.tensor([[3]], dtype=torch.long, device=device)  # EOS only\n",
    "        \n",
    "        # Create dummy output for compatibility\n",
    "        vocab_size = self.decoder.vocab_size\n",
    "        output_probs = torch.zeros(1, len(best_seq), vocab_size, device=device)\n",
    "        for i, token in enumerate(best_seq):\n",
    "            output_probs[0, i, token] = 1.0\n",
    "        \n",
    "        return output_probs\n",
    "    \n",
    "    def greedy_decode(self, encoder_outputs, encoder_mask, decoder_hidden, \n",
    "                     decoder_cell, max_length=50):\n",
    "        \n",
    "        \"\"\"Greedy decoding with repetition penalty\"\"\"\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        device = encoder_outputs.device\n",
    "        vocab_size = self.decoder.vocab_size\n",
    "        \n",
    "        outputs = []\n",
    "        input_token = torch.full((batch_size, 1), 2, dtype=torch.long, device=device)  # SOS\n",
    "        hidden_state = (decoder_hidden, decoder_cell)\n",
    "        \n",
    "        # Track recent tokens for repetition penalty\n",
    "        recent_tokens = []\n",
    "        \n",
    "        for step in range(max_length):\n",
    "            \n",
    "            output, hidden_state, _ = self.decoder(\n",
    "                input_token, hidden_state, encoder_outputs, encoder_mask\n",
    "            )\n",
    "            \n",
    "            # Apply repetition penalty\n",
    "            if len(recent_tokens) > 0\n",
    "            \n",
    "                for recent_token in recent_tokens[-3:]:  # Penalize last 3 tokens\n",
    "                    output[0, 0, recent_token] -= 5.0\n",
    "            \n",
    "            outputs.append(output)\n",
    "            \n",
    "            # Get next token\n",
    "            input_token = output.argmax(dim=-1)\n",
    "            token_id = input_token.item() if batch_size == 1 else input_token[0].item()\n",
    "            \n",
    "            recent_tokens.append(token_id)\n",
    "            \n",
    "            # Stop if EOS token\n",
    "            if token_id == 3:\n",
    "                \n",
    "                break\n",
    "        \n",
    "        return torch.cat(outputs, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T19:26:32.390532Z",
     "iopub.status.busy": "2025-09-24T19:26:32.390341Z",
     "iopub.status.idle": "2025-09-24T19:26:32.413422Z",
     "shell.execute_reply": "2025-09-24T19:26:32.412603Z",
     "shell.execute_reply.started": "2025-09-24T19:26:32.390517Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===================== EVALUATION METRICS =====================\n",
    "\n",
    "def calculate_perplexity(model, data_loader, criterion, device):\n",
    "    \n",
    "    \"\"\"Calculate perplexity\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            urdu_seq = batch['urdu'].to(device)\n",
    "            roman_seq = batch['roman'].to(device)\n",
    "            \n",
    "            decoder_target = roman_seq[:, 1:]\n",
    "            outputs = model(urdu_seq, roman_seq, teacher_forcing_ratio=0.0)\n",
    "            \n",
    "            loss = criterion(outputs.reshape(-1, outputs.size(-1)), decoder_target.reshape(-1))\n",
    "            non_pad_tokens = (decoder_target != 0).sum().item()\n",
    "            \n",
    "            total_loss += loss.item() * non_pad_tokens\n",
    "            total_tokens += non_pad_tokens\n",
    "    \n",
    "    if total_tokens == 0:\n",
    "        \n",
    "        return float('inf')\n",
    "    \n",
    "    avg_loss = total_loss / total_tokens\n",
    "    return math.exp(avg_loss)\n",
    "\n",
    "def calculate_cer(predictions, targets, tokenizer):\n",
    "    \n",
    "    \"\"\"Calculate Character Error Rate\"\"\"\n",
    "    def edit_distance_cer(s1, s2):\n",
    "        if len(s1) < len(s2):\n",
    "            return edit_distance_cer(s2, s1)\n",
    "        \n",
    "        if len(s2) == 0:\n",
    "            return len(s1)\n",
    "        \n",
    "        previous_row = range(len(s2) + 1)\n",
    "        \n",
    "        for i, c1 in enumerate(s1):\n",
    "            \n",
    "            current_row = [i + 1]\n",
    "            for j, c2 in enumerate(s2):\n",
    "                insertions = previous_row[j + 1] + 1\n",
    "                deletions = current_row[j] + 1\n",
    "                substitutions = previous_row[j] + (c1 != c2)\n",
    "                current_row.append(min(insertions, deletions, substitutions))\n",
    "            previous_row = current_row\n",
    "        \n",
    "        return previous_row[-1]\n",
    "    \n",
    "    total_chars = 0\n",
    "    total_errors = 0\n",
    "    \n",
    "    for pred, target in zip(predictions, targets):\n",
    "        \n",
    "        # Convert to lists and remove special tokens\n",
    "        if hasattr(pred, 'tolist'):\n",
    "            pred_tokens = pred.tolist()\n",
    "        else:\n",
    "            pred_tokens = list(pred)\n",
    "        \n",
    "        if hasattr(target, 'tolist'):\n",
    "            target_tokens = target.tolist()\n",
    "        else:\n",
    "            target_tokens = list(target)\n",
    "        \n",
    "        pred_clean = [t for t in pred_tokens if t not in [0, 1, 2, 3]]\n",
    "        target_clean = [t for t in target_tokens if t not in [0, 1, 2, 3]]\n",
    "        \n",
    "        if len(pred_clean) > 0 and len(target_clean) > 0:\n",
    "            \n",
    "            pred_text = tokenizer.decode(pred_clean)\n",
    "            target_text = tokenizer.decode(target_clean)\n",
    "            \n",
    "            errors = edit_distance_cer(pred_text, target_text)\n",
    "            total_errors += errors\n",
    "            total_chars += len(target_text)\n",
    "    \n",
    "    return total_errors / total_chars if total_chars > 0 else 1.0\n",
    "\n",
    "def edit_distance(s1, s2):\n",
    "    \n",
    "    \"\"\"Calculate edit distance (Levenshtein distance) between two strings\"\"\"\n",
    "    if len(s1) < len(s2):\n",
    "        return edit_distance(s2, s1)\n",
    "    \n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    \n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]\n",
    "\n",
    "def calculate_bleu_score(predictions, targets, tokenizer):\n",
    "    \n",
    "    \"\"\"Calculate BLEU score properly\"\"\"\n",
    "    from collections import Counter\n",
    "    \n",
    "    def get_ngrams(tokens, n):\n",
    "        if len(tokens) < n:\n",
    "            return []\n",
    "        return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "    \n",
    "    def calculate_bleu(pred_tokens, target_tokens, max_n=4):\n",
    "        if len(pred_tokens) == 0 or len(target_tokens) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        precisions = []\n",
    "        for n in range(1, min(max_n + 1, len(pred_tokens) + 1)):\n",
    "            pred_ngrams = Counter(get_ngrams(pred_tokens, n))\n",
    "            target_ngrams = Counter(get_ngrams(target_tokens, n))\n",
    "            \n",
    "            if len(pred_ngrams) == 0:\n",
    "                \n",
    "                precisions.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            matches = sum((pred_ngrams & target_ngrams).values())\n",
    "            total = sum(pred_ngrams.values())\n",
    "            precision = matches / total if total > 0 else 0.0\n",
    "            precisions.append(precision)\n",
    "        \n",
    "        # Brevity penalty\n",
    "        if len(pred_tokens) == 0:\n",
    "            \n",
    "            bp = 0.0\n",
    "        elif len(pred_tokens) < len(target_tokens):\n",
    "            \n",
    "            bp = math.exp(1 - len(target_tokens) / len(pred_tokens))\n",
    "        else:\n",
    "            \n",
    "            bp = 1.0\n",
    "        \n",
    "        # Geometric mean of precisions\n",
    "        if precisions and all(p > 0 for p in precisions):\n",
    "            \n",
    "            geo_mean = math.exp(sum(math.log(p) for p in precisions) / len(precisions))\n",
    "            score = bp * geo_mean\n",
    "        else:\n",
    "            \n",
    "            score = 0.0\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    total_score = 0.0\n",
    "    count = 0\n",
    "    total_errors = 0\n",
    "    total_chars = 0\n",
    "    \n",
    "    for pred, target in zip(predictions, targets):\n",
    "        \n",
    "        # Handle tensors\n",
    "        if hasattr(pred, 'cpu'):\n",
    "            pred = pred.cpu()\n",
    "        if hasattr(target, 'cpu'):\n",
    "            target = target.cpu()\n",
    "        \n",
    "        # Convert to lists\n",
    "        if hasattr(pred, 'tolist'):\n",
    "            pred_tokens = pred.tolist()\n",
    "        else:\n",
    "            \n",
    "            pred_tokens = list(pred)\n",
    "        \n",
    "        if hasattr(target, 'tolist'):\n",
    "            \n",
    "            target_tokens = target.tolist()\n",
    "        else:\n",
    "            \n",
    "            target_tokens = list(target)\n",
    "        \n",
    "        # Remove special tokens\n",
    "        pred_clean = [t for t in pred_tokens if t not in [0, 1, 2, 3]]\n",
    "        target_clean = [t for t in target_tokens if t not in [0, 1, 2, 3]]\n",
    "        \n",
    "        if len(pred_clean) > 0 and len(target_clean) > 0:\n",
    "            \n",
    "            # Calculate BLEU score\n",
    "            bleu = calculate_bleu(pred_clean, target_clean)\n",
    "            total_score += bleu\n",
    "            count += 1\n",
    "            \n",
    "            # Calculate CER (Character Error Rate)\n",
    "            pred_text = tokenizer.decode(pred_clean)\n",
    "            target_text = tokenizer.decode(target_clean)\n",
    "            \n",
    "            if len(pred_text) > 0 and len(target_text) > 0:\n",
    "                errors = edit_distance(pred_text, target_text)\n",
    "                total_errors += errors\n",
    "                total_chars += len(target_text)\n",
    "    \n",
    "    # Return BLEU score (not CER)\n",
    "    return total_score / count if count > 0 else 0.0\n",
    "\n",
    "def calculate_accuracy(predictions, targets, tokenizer):\n",
    "    \n",
    "    \"\"\"Calculate token-level and sequence-level accuracy\"\"\"\n",
    "    total_tokens = 0\n",
    "    correct_tokens = 0\n",
    "    total_sequences = 0\n",
    "    correct_sequences = 0\n",
    "    \n",
    "    for pred, target in zip(predictions, targets):\n",
    "        \n",
    "        # Convert to lists and remove special tokens\n",
    "        if hasattr(pred, 'tolist'):\n",
    "            pred_tokens = pred.tolist()\n",
    "        else:\n",
    "            pred_tokens = list(pred)\n",
    "        \n",
    "        if hasattr(target, 'tolist'):\n",
    "            \n",
    "            target_tokens = target.tolist()\n",
    "        else:\n",
    "            target_tokens = list(target)\n",
    "        \n",
    "        # Remove special tokens (padding, start, end, unknown)\n",
    "        pred_clean = [t for t in pred_tokens if t not in [0, 1, 2, 3]]\n",
    "        target_clean = [t for t in target_tokens if t not in [0, 1, 2, 3]]\n",
    "        \n",
    "        if len(pred_clean) > 0 and len(target_clean) > 0:\n",
    "            \n",
    "            # Token-level accuracy\n",
    "            min_len = min(len(pred_clean), len(target_clean))\n",
    "            max_len = max(len(pred_clean), len(target_clean))\n",
    "            \n",
    "            # Count matching tokens up to the minimum length\n",
    "            matches = sum(1 for i in range(min_len) if pred_clean[i] == target_clean[i])\n",
    "            correct_tokens += matches\n",
    "            total_tokens += max_len  # Use max length to penalize length differences\n",
    "            \n",
    "            # Sequence-level accuracy (exact match)\n",
    "            if pred_clean == target_clean:\n",
    "                correct_sequences += 1\n",
    "            total_sequences += 1\n",
    "    \n",
    "    token_accuracy = correct_tokens / total_tokens if total_tokens > 0 else 0.0\n",
    "    sequence_accuracy = correct_sequences / total_sequences if total_sequences > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'token_accuracy': token_accuracy,\n",
    "        'sequence_accuracy': sequence_accuracy\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T19:26:32.414265Z",
     "iopub.status.busy": "2025-09-24T19:26:32.414071Z",
     "iopub.status.idle": "2025-09-24T19:26:32.429508Z",
     "shell.execute_reply": "2025-09-24T19:26:32.428801Z",
     "shell.execute_reply.started": "2025-09-24T19:26:32.414250Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(model, train_loader, optimizer, criterion, teacher_forcing_ratio=0.5):\n",
    "    \n",
    "    \"\"\"Train one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        \n",
    "        urdu_seq = batch['urdu'].to(device)\n",
    "        roman_seq = batch['roman'].to(device)\n",
    "        \n",
    "        decoder_target = roman_seq[:, 1:]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(urdu_seq, roman_seq, teacher_forcing_ratio)\n",
    "        \n",
    "        loss = criterion(outputs.reshape(-1, outputs.size(-1)), decoder_target.reshape(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, roman_tokenizer):\n",
    "    \n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_tokens = 0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            urdu_seq = batch['urdu'].to(device)\n",
    "            roman_seq = batch['roman'].to(device)\n",
    "            \n",
    "            decoder_target = roman_seq[:, 1:]\n",
    "            \n",
    "            # Loss calculation - now properly handles padding tokens\n",
    "            outputs = model(urdu_seq, roman_seq, teacher_forcing_ratio=0.0)\n",
    "            loss = criterion(outputs.reshape(-1, outputs.size(-1)), decoder_target.reshape(-1))\n",
    "            non_pad_tokens = (decoder_target != 0).sum().item()\n",
    "            \n",
    "            total_loss += loss.item() * non_pad_tokens\n",
    "            total_tokens += non_pad_tokens\n",
    "            \n",
    "            # Predictions for metrics\n",
    "            pred_tokens = outputs.argmax(dim=-1)\n",
    "            for i in range(pred_tokens.size(0)):\n",
    "                predictions.append(pred_tokens[i].cpu())\n",
    "                targets.append(decoder_target[i].cpu())\n",
    "    \n",
    "    avg_loss = total_loss / total_tokens if total_tokens > 0 else float('inf')\n",
    "    bleu = calculate_bleu_score(predictions, targets, roman_tokenizer)\n",
    "    perplexity = calculate_perplexity(model, data_loader, criterion, device)\n",
    "    cer = calculate_cer(predictions, targets, roman_tokenizer)\n",
    "    accuracy_metrics = calculate_accuracy(predictions, targets, roman_tokenizer)\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'bleu': bleu,\n",
    "        'perplexity': perplexity,\n",
    "        'cer': cer,\n",
    "        'token_accuracy': accuracy_metrics['token_accuracy'],\n",
    "        'sequence_accuracy': accuracy_metrics['sequence_accuracy']\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Translation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T19:26:32.430348Z",
     "iopub.status.busy": "2025-09-24T19:26:32.430171Z",
     "iopub.status.idle": "2025-09-24T19:26:32.441029Z",
     "shell.execute_reply": "2025-09-24T19:26:32.440446Z",
     "shell.execute_reply.started": "2025-09-24T19:26:32.430333Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def translate_text(model, text, urdu_tokenizer, roman_tokenizer):\n",
    "    \n",
    "    \"\"\"Translate a single text\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    tokens = urdu_tokenizer.encode(text, out_type=int)\n",
    "    input_tensor = torch.tensor([tokens], dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        predicted_tokens = output.argmax(dim=-1).squeeze().cpu().tolist()\n",
    "        \n",
    "        # Truncate prediction at first EOS token if present (EOS id = 3)\n",
    "        try:\n",
    "            eos_index = predicted_tokens.index(3)\n",
    "            predicted_tokens = predicted_tokens[:eos_index]\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "        # Remove special tokens except EOS (PAD=0, UNK=1, BOS=2)\n",
    "        clean_tokens = [t for t in predicted_tokens if t not in [0, 1, 2]]\n",
    "        \n",
    "        translated_text = roman_tokenizer.decode(clean_tokens)\n",
    "    \n",
    "    return translated_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Experiment Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T19:26:32.441869Z",
     "iopub.status.busy": "2025-09-24T19:26:32.441665Z",
     "iopub.status.idle": "2025-09-24T19:26:32.457748Z",
     "shell.execute_reply": "2025-09-24T19:26:32.457143Z",
     "shell.execute_reply.started": "2025-09-24T19:26:32.441854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_experiment(config, splits, urdu_tokenizer, roman_tokenizer):\n",
    "    \n",
    "    \"\"\"Run a single experiment with given configuration\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Running experiment: {config['name']}\")\n",
    "    print(f\"Config: {config}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    test_results = None  # Initialize test_results to avoid UnboundLocalError\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = TranslationDataset(\n",
    "            splits['train']['urdu'], splits['train']['roman'], \n",
    "            urdu_tokenizer, roman_tokenizer\n",
    "        )\n",
    "        val_dataset = TranslationDataset(\n",
    "            splits['val']['urdu'], splits['val']['roman'], \n",
    "            urdu_tokenizer, roman_tokenizer\n",
    "        )\n",
    "        test_dataset = TranslationDataset(\n",
    "            splits['test']['urdu'], splits['test']['roman'], \n",
    "            urdu_tokenizer, roman_tokenizer\n",
    "        )\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], \n",
    "                                 shuffle=True, collate_fn=collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], \n",
    "                               shuffle=False, collate_fn=collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], \n",
    "                                shuffle=False, collate_fn=collate_fn)\n",
    "        \n",
    "        # Initialize model\n",
    "        model = Seq2SeqModel(\n",
    "            urdu_vocab_size=urdu_tokenizer.get_piece_size(),\n",
    "            roman_vocab_size=roman_tokenizer.get_piece_size(),\n",
    "            embed_dim=config['embed_dim'],\n",
    "            hidden_dim=config['hidden_dim'],\n",
    "            dropout=config['dropout']\n",
    "        ).to(device)\n",
    "        \n",
    "        \n",
    "        # Initialize optimizer and criterion\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "        \n",
    "        # Training loop\n",
    "        best_val_bleu = 0\n",
    "        patience = 5\n",
    "        patience_counter = 0\n",
    "        \n",
    "        train_losses = []\n",
    "        val_metrics = []\n",
    "        \n",
    "        for epoch in range(config['epochs']):\n",
    "            \n",
    "            # Train\n",
    "            train_loss = train_epoch(model, train_loader, optimizer, criterion, \n",
    "                                   config.get('teacher_forcing_ratio', 0.5))\n",
    "            train_losses.append(train_loss)\n",
    "            \n",
    "            # Validate\n",
    "            val_results = evaluate_model(model, val_loader, criterion, roman_tokenizer)\n",
    "            val_metrics.append(val_results)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{config['epochs']}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"Val Loss: {val_results['loss']:.4f}, BLEU: {val_results['bleu']:.4f}, \"\n",
    "                  f\"Perplexity: {val_results['perplexity']:.2f}, CER: {val_results['cer']:.4f}\")\n",
    "            print(f\"Token Accuracy: {val_results['token_accuracy']:.4f}, \"\n",
    "                  f\"Sequence Accuracy: {val_results['sequence_accuracy']:.4f}\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_results['bleu'] > best_val_bleu:\n",
    "                \n",
    "                best_val_bleu = val_results['bleu']\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                torch.save(model.state_dict(), f\"best_model_{config['name']}.pth\")\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "        \n",
    "        # Load best model for testing\n",
    "        try:\n",
    "            \n",
    "            model.load_state_dict(torch.load(f\"best_model_{config['name']}.pth\"))\n",
    "            \n",
    "            # Test evaluation\n",
    "            test_results = evaluate_model(model, test_loader, criterion, roman_tokenizer)\n",
    "            \n",
    "            print(f\"\\nFinal Test Results for {config['name']}:\")\n",
    "            print(f\"Test Loss: {test_results['loss']:.4f}\")\n",
    "            print(f\"Test BLEU: {test_results['bleu']:.4f}\")\n",
    "            print(f\"Test Perplexity: {test_results['perplexity']:.2f}\")\n",
    "            print(f\"Test CER: {test_results['cer']:.4f}\")\n",
    "            print(f\"Test Token Accuracy: {test_results['token_accuracy']:.4f}\")\n",
    "            print(f\"Test Sequence Accuracy: {test_results['sequence_accuracy']:.4f}\")\n",
    "            \n",
    "            # Sample translations\n",
    "            print(f\"\\nSample Translations for {config['name']}:\")\n",
    "            sample_texts = splits['test']['urdu'][:5]\n",
    "            for i, urdu_text in enumerate(sample_texts):\n",
    "                translation = translate_text(model, urdu_text, urdu_tokenizer, roman_tokenizer)\n",
    "                actual = splits['test']['roman'][i]\n",
    "                print(f\"Urdu: {urdu_text}\")\n",
    "                print(f\"Predicted: {translation}\")\n",
    "                print(f\"Actual: {actual}\")\n",
    "                print(\"-\" * 50)\n",
    "                \n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f\"Error during model loading or testing: {e}\")\n",
    "            # Create default test results if testing fails\n",
    "            \n",
    "            test_results = {\n",
    "                'loss': float('inf'),\n",
    "                'bleu': 0.0,\n",
    "                'perplexity': float('inf'),\n",
    "                'cer': 1.0,\n",
    "                'token_accuracy': 0.0,\n",
    "                'sequence_accuracy': 0.0\n",
    "            }\n",
    "    \n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"Error during training: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Return default values if experiment fails completely\n",
    "        return {\n",
    "            'config': config,\n",
    "            'train_losses': [],\n",
    "            'val_metrics': [],\n",
    "            'test_results': {\n",
    "                'loss': float('inf'),\n",
    "                'bleu': 0.0,\n",
    "                'perplexity': float('inf'),\n",
    "                'cer': 1.0,\n",
    "                'token_accuracy': 0.0,\n",
    "                'sequence_accuracy': 0.0\n",
    "            },\n",
    "            'best_val_bleu': 0.0\n",
    "        }\n",
    "    \n",
    "    # Ensure test_results is never None\n",
    "    if test_results is None:\n",
    "        \n",
    "        test_results = {\n",
    "            'loss': float('inf'),\n",
    "            'bleu': 0.0,\n",
    "            'perplexity': float('inf'),\n",
    "            'cer': 1.0,\n",
    "            'token_accuracy': 0.0,\n",
    "            'sequence_accuracy': 0.0\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'config': config,\n",
    "        'train_losses': train_losses,\n",
    "        'val_metrics': val_metrics,\n",
    "        'test_results': test_results,\n",
    "        'best_val_bleu': best_val_bleu\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. TOKENIZER CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T19:26:32.458563Z",
     "iopub.status.busy": "2025-09-24T19:26:32.458370Z",
     "iopub.status.idle": "2025-09-24T19:26:32.477262Z",
     "shell.execute_reply": "2025-09-24T19:26:32.476497Z",
     "shell.execute_reply.started": "2025-09-24T19:26:32.458537Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===================== ENHANCED TOKENIZER CREATION =====================\n",
    "\n",
    "def create_tokenizers(urdu_texts, roman_texts, vocab_size=8000):\n",
    "    \"\"\"Create SentencePiece tokenizers for Urdu and Roman text\"\"\"\n",
    "    import tempfile\n",
    "    import os\n",
    "    \n",
    "    # Create temporary files for training data\n",
    "    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt', encoding='utf-8') as f:\n",
    "        urdu_temp_file = f.name\n",
    "        for text in urdu_texts:\n",
    "            f.write(text + '\\n')\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt', encoding='utf-8') as f:\n",
    "        roman_temp_file = f.name\n",
    "        for text in roman_texts:\n",
    "            f.write(text + '\\n')\n",
    "    \n",
    "    try:\n",
    "        # Train Urdu tokenizer\n",
    "        spm.SentencePieceTrainer.train(\n",
    "            input=urdu_temp_file,\n",
    "            model_prefix='urdu_tokenizer',\n",
    "            vocab_size=vocab_size,\n",
    "            character_coverage=1.0,\n",
    "            model_type='bpe',\n",
    "            pad_id=0,\n",
    "            unk_id=1,\n",
    "            bos_id=2,\n",
    "            eos_id=3\n",
    "        )\n",
    "        \n",
    "        # Train Roman tokenizer\n",
    "        spm.SentencePieceTrainer.train(\n",
    "            input=roman_temp_file,\n",
    "            model_prefix='roman_tokenizer',\n",
    "            vocab_size=vocab_size,\n",
    "            character_coverage=1.0,\n",
    "            model_type='bpe',\n",
    "            pad_id=0,\n",
    "            unk_id=1,\n",
    "            bos_id=2,\n",
    "            eos_id=3\n",
    "        )\n",
    "        \n",
    "        # Load tokenizers\n",
    "        urdu_tokenizer = spm.SentencePieceProcessor()\n",
    "        urdu_tokenizer.load('urdu_tokenizer.model')\n",
    "        \n",
    "        roman_tokenizer = spm.SentencePieceProcessor()\n",
    "        roman_tokenizer.load('roman_tokenizer.model')\n",
    "        \n",
    "        print(f\"Urdu tokenizer vocabulary size: {urdu_tokenizer.get_piece_size()}\")\n",
    "        print(f\"Roman tokenizer vocabulary size: {roman_tokenizer.get_piece_size()}\")\n",
    "        \n",
    "        return urdu_tokenizer, roman_tokenizer\n",
    "        \n",
    "    finally:\n",
    "        # Clean up temporary files\n",
    "        try:\n",
    "            os.unlink(urdu_temp_file)\n",
    "            os.unlink(roman_temp_file)\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T19:29:08.106978Z",
     "iopub.status.busy": "2025-09-24T19:29:08.106679Z",
     "iopub.status.idle": "2025-09-24T19:29:08.120198Z",
     "shell.execute_reply": "2025-09-24T19:29:08.119395Z",
     "shell.execute_reply.started": "2025-09-24T19:29:08.106958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    \n",
    "    \"\"\"Main function to run all experiments\"\"\"\n",
    "    print(\"Starting Urdu to Roman Transliteration Experiments\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    print(\"Loading data...\")\n",
    "    processor = UrduRomanDataProcessor(\"/kaggle/input/poet-dataset/dataset\")\n",
    "    processor.load_data()\n",
    "    processor.preprocess_data()\n",
    "    \n",
    "    # Create train/val/test splits\n",
    "    print(\"Creating data splits...\")\n",
    "    splits = processor.split_data()\n",
    "    \n",
    "    print(f\"Train samples: {len(splits['train']['urdu'])}\")\n",
    "    print(f\"Validation samples: {len(splits['val']['urdu'])}\")\n",
    "    print(f\"Test samples: {len(splits['test']['urdu'])}\")\n",
    "    \n",
    "    # Create tokenizers\n",
    "    print(\"Creating tokenizers...\")\n",
    "    urdu_tokenizer, roman_tokenizer = create_tokenizers(\n",
    "        splits['train']['urdu'] + splits['val']['urdu'], \n",
    "        splits['train']['roman'] + splits['val']['roman']\n",
    "    )\n",
    "    \n",
    "    # Interactive teacher forcing prompt\n",
    "    print(\"\\nTeacher Forcing Setup\")\n",
    "    \n",
    "    use_tf_input = input(\"Use teacher forcing during training? (y/n, default y): \").strip().lower()\n",
    "    if use_tf_input == 'n':\n",
    "        tf_ratio = 0.0\n",
    "        print(\"Teacher forcing disabled (ratio = 0.0)\")\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        tf_ratio_input = input(\"Enter teacher forcing ratio [0.0-1.0] (default 0.5): \").strip()\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            tf_ratio = float(tf_ratio_input) if tf_ratio_input else 0.5\n",
    "            \n",
    "        except ValueError:\n",
    "            \n",
    "            print(\"Invalid input. Defaulting teacher forcing ratio to 0.5\")\n",
    "            tf_ratio = 0.5\n",
    "        tf_ratio = max(0.0, min(1.0, tf_ratio))\n",
    "        print(f\"Using teacher forcing ratio: {tf_ratio}\")\n",
    "    \n",
    "    # Define experiment configurations\n",
    "    configs = [\n",
    "        {\n",
    "            'name': 'baseline',\n",
    "            'embed_dim': 128,\n",
    "            'hidden_dim': 256,\n",
    "            'dropout': 0.1,\n",
    "            'learning_rate': 0.001,\n",
    "            'batch_size': 32,\n",
    "            'epochs': 10,\n",
    "            'teacher_forcing_ratio': tf_ratio\n",
    "        }#,\n",
    " #       {\n",
    "  #          'name': 'larger_model',\n",
    "   #         'embed_dim': 256,\n",
    "    #        'hidden_dim': 512,\n",
    "     #       'dropout': 0.2,\n",
    "      #      'learning_rate': 0.0005,\n",
    "       #     'batch_size': 16,\n",
    "        #    'epochs': 20,\n",
    "         #   'teacher_forcing_ratio': tf_ratio\n",
    " #       },\n",
    "  #      {\n",
    "   #         'name': 'high_dropout',\n",
    "    #        'embed_dim': 128,\n",
    "     #       'hidden_dim': 256,\n",
    "      #      'dropout': 0.3,\n",
    "       #     'learning_rate': 0.001,\n",
    "        #    'batch_size': 32,\n",
    "         #   'epochs': 20,\n",
    "          #  'teacher_forcing_ratio': tf_ratio\n",
    "       # }\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    # Run experiments\n",
    "    results = []\n",
    "    for config in configs:\n",
    "        try:\n",
    "            result = run_experiment(config, splits, urdu_tokenizer, roman_tokenizer)\n",
    "            # Only add results that have both test_results and config\n",
    "            if result and 'test_results' in result and 'config' in result:\n",
    "                results.append(result)\n",
    "            else:\n",
    "                print(f\"Warning: Experiment {config['name']} returned incomplete results\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error running experiment {config['name']}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXPERIMENT SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No experiments completed successfully.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"{'Experiment':<20} {'BLEU':<8} {'CER':<8} {'Perplexity':<12} {'Token Acc':<10} {'Seq Acc':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for result in results:\n",
    "        config = result.get('config', {})\n",
    "        test_results = result.get('test_results', {})\n",
    "        \n",
    "        name = config.get('name', 'Unknown')\n",
    "        bleu = test_results.get('bleu', 0.0)\n",
    "        cer = test_results.get('cer', 1.0)\n",
    "        perplexity = test_results.get('perplexity', float('inf'))\n",
    "        token_acc = test_results.get('token_accuracy', 0.0)\n",
    "        seq_acc = test_results.get('sequence_accuracy', 0.0)\n",
    "        \n",
    "        # Handle infinite perplexity for display\n",
    "        perp_str = f\"{perplexity:.2f}\" if perplexity != float('inf') else \"inf\"\n",
    "        \n",
    "        print(f\"{name:<20} {bleu:<8.4f} {cer:<8.4f} {perp_str:<12} {token_acc:<10.4f} {seq_acc:<10.4f}\")\n",
    "    \n",
    "    # Find best model\n",
    "    if results:\n",
    "        best_result = max(results, key=lambda x: x.get('test_results', {}).get('bleu', 0))\n",
    "        best_config = best_result.get('config', {})\n",
    "        best_test = best_result.get('test_results', {})\n",
    "        \n",
    "        print(f\"\\nBest Model: {best_config.get('name', 'Unknown')}\")\n",
    "        print(f\"Best BLEU Score: {best_test.get('bleu', 0.0):.4f}\")\n",
    "        print(f\"Best CER: {best_test.get('cer', 1.0):.4f}\")\n",
    "        print(f\"Best Token Accuracy: {best_test.get('token_accuracy', 0.0):.4f}\")\n",
    "        print(f\"Best Sequence Accuracy: {best_test.get('sequence_accuracy', 0.0):.4f}\")\n",
    "    \n",
    "    print(\"\\nExperiments completed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T19:29:13.233278Z",
     "iopub.status.busy": "2025-09-24T19:29:13.232536Z",
     "iopub.status.idle": "2025-09-24T19:35:16.722871Z",
     "shell.execute_reply": "2025-09-24T19:35:16.722281Z",
     "shell.execute_reply.started": "2025-09-24T19:29:13.233254Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Urdu to Roman Transliteration Experiments\n",
      "============================================================\n",
      "Loading data...\n",
      "Loading data from urdu_ghazals_rekhta dataset...\n",
      "Loaded 21003 text pairs\n",
      "Preprocessing and filtering data...\n",
      "After preprocessing: 20893 pairs\n",
      "Creating data splits...\n",
      "Data split - Train: 10446 (50.0%), Val: 5223 (25.0%), Test: 5224 (25.0%)\n",
      "Train samples: 10446\n",
      "Validation samples: 5223\n",
      "Test samples: 5224\n",
      "Creating tokenizers...\n",
      "Urdu tokenizer vocabulary size: 8000\n",
      "Roman tokenizer vocabulary size: 8000\n",
      "\n",
      "Teacher Forcing Setup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use teacher forcing during training? (y/n, default y):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher forcing disabled (ratio = 0.0)\n",
      "\n",
      "==================================================\n",
      "Running experiment: baseline\n",
      "Config: {'name': 'baseline', 'embed_dim': 128, 'hidden_dim': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 10, 'teacher_forcing_ratio': 0.0}\n",
      "==================================================\n",
      "Epoch 1/10\n",
      "Train Loss: 5.2152\n",
      "Val Loss: 4.1726, BLEU: 0.0251, Perplexity: 64.88, CER: 0.6314\n",
      "Token Accuracy: 0.2838, Sequence Accuracy: 0.0000\n",
      "Epoch 2/10\n",
      "Train Loss: 3.4606\n",
      "Val Loss: 3.2776, BLEU: 0.1506, Perplexity: 26.51, CER: 0.5519\n",
      "Token Accuracy: 0.3816, Sequence Accuracy: 0.0134\n",
      "Epoch 3/10\n",
      "Train Loss: 2.6011\n",
      "Val Loss: 2.9124, BLEU: 0.2287, Perplexity: 18.40, CER: 0.4623\n",
      "Token Accuracy: 0.4314, Sequence Accuracy: 0.0498\n",
      "Epoch 4/10\n",
      "Train Loss: 2.0472\n",
      "Val Loss: 2.6903, BLEU: 0.2913, Perplexity: 14.74, CER: 0.4177\n",
      "Token Accuracy: 0.4675, Sequence Accuracy: 0.0758\n",
      "Epoch 5/10\n",
      "Train Loss: 1.6419\n",
      "Val Loss: 2.5951, BLEU: 0.3233, Perplexity: 13.40, CER: 0.3572\n",
      "Token Accuracy: 0.4977, Sequence Accuracy: 0.0898\n",
      "Epoch 6/10\n",
      "Train Loss: 1.3426\n",
      "Val Loss: 2.5651, BLEU: 0.3516, Perplexity: 13.00, CER: 0.3298\n",
      "Token Accuracy: 0.5096, Sequence Accuracy: 0.0999\n",
      "Epoch 7/10\n",
      "Train Loss: 1.1356\n",
      "Val Loss: 2.5258, BLEU: 0.3822, Perplexity: 12.50, CER: 0.3094\n",
      "Token Accuracy: 0.5303, Sequence Accuracy: 0.1133\n",
      "Epoch 8/10\n",
      "Train Loss: 0.9867\n",
      "Val Loss: 2.4788, BLEU: 0.3978, Perplexity: 11.93, CER: 0.3036\n",
      "Token Accuracy: 0.5372, Sequence Accuracy: 0.1229\n",
      "Epoch 9/10\n",
      "Train Loss: 0.8680\n",
      "Val Loss: 2.4598, BLEU: 0.4342, Perplexity: 11.70, CER: 0.2689\n",
      "Token Accuracy: 0.5597, Sequence Accuracy: 0.1557\n",
      "Epoch 10/10\n",
      "Train Loss: 0.7684\n",
      "Val Loss: 2.4873, BLEU: 0.4230, Perplexity: 12.03, CER: 0.2751\n",
      "Token Accuracy: 0.5534, Sequence Accuracy: 0.1421\n",
      "\n",
      "Final Test Results for baseline:\n",
      "Test Loss: 2.5235\n",
      "Test BLEU: 0.4212\n",
      "Test Perplexity: 12.47\n",
      "Test CER: 0.2767\n",
      "Test Token Accuracy: 0.5390\n",
      "Test Sequence Accuracy: 0.1453\n",
      "\n",
      "Sample Translations for baseline:\n",
      "Urdu:       \n",
      "Predicted: ai hud-e-dil-dil haidil-e-dost\n",
      "Actual: ai hud dard-e-dil hai bahshish-e-dost\n",
      "--------------------------------------------------\n",
      "Urdu:      \n",
      "Predicted: zindag ab to ik tamann de\n",
      "Actual: zindag ab to ik tamann de\n",
      "--------------------------------------------------\n",
      "Urdu:       \n",
      "Predicted: kais baith hai chhup ke patto me\n",
      "Actual: kais baith hai chhup ke patto me\n",
      "--------------------------------------------------\n",
      "Urdu:         \n",
      "Predicted: 'firq' aksar badal ko hai milt hai ko\n",
      "Actual: 'firq' aksar badal kar bhes milt hai ko kfir\n",
      "--------------------------------------------------\n",
      "Urdu:          \n",
      "Predicted: haath rakh de mir kho pe ki niid aa jaa.e\n",
      "Actual: haath rakh de mir kho pe ki niid aa jaa.e\n",
      "--------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT SUMMARY\n",
      "================================================================================\n",
      "Experiment           BLEU     CER      Perplexity   Token Acc  Seq Acc   \n",
      "--------------------------------------------------------------------------------\n",
      "baseline             0.4212   0.2767   12.47        0.5390     0.1453    \n",
      "\n",
      "Best Model: baseline\n",
      "Best BLEU Score: 0.4212\n",
      "Best CER: 0.2767\n",
      "Best Token Accuracy: 0.5390\n",
      "Best Sequence Accuracy: 0.1453\n",
      "\n",
      "Experiments completed!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T05:04:40.116372Z",
     "iopub.status.busy": "2025-09-25T05:04:40.116051Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T05:04:40.116372Z",
     "iopub.status.busy": "2025-09-25T05:04:40.116051Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting Urdu to Roman Transliteration Experiments (xLSTM + Augmentation)\n",
      "============================================================\n",
      "Loading data...\n",
      "Loading data from urdu_ghazals_rekhta dataset...\n",
      "Loaded 21003 text pairs\n",
      "Preprocessing and filtering data...\n",
      "After preprocessing: 20893 pairs\n",
      "Creating data splits...\n",
      "Data split - Train: 10446 (50.0%), Val: 5223 (25.0%), Test: 5224 (25.0%)\n",
      "Train samples: 10446\n",
      "Validation samples: 5223\n",
      "Test samples: 5224\n",
      "Creating tokenizers...\n",
      "Urdu tokenizer vocabulary size: 8000\n",
      "Roman tokenizer vocabulary size: 8000\n",
      "\n",
      "Teacher Forcing Setup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use teacher forcing during training? (y/n, default y):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher forcing disabled (ratio = 0.0)\n",
      "\n",
      "==================================================\n",
      "Running experiment: xlstm_aug\n",
      "Config: {'name': 'xlstm_aug', 'model': 'xlstm', 'embed_dim': 128, 'hidden_dim': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 15, 'teacher_forcing_ratio': 0.0, 'augmentation': {'enabled': True, 'aug_factor': 0.7, 'roman_variants_per_sample': 1, 'apply_urdu_noise': True, 'apply_roman_noise': True, 'seed': 42}}\n",
      "==================================================\n",
      "Augmented training set: 25070 samples (from 10446)\n",
      "Epoch 1/15\n",
      "Train Loss: 4.8282\n",
      "Val Loss: 3.3598, BLEU: 0.0868, Perplexity: 28.78, CER: 0.5706\n",
      "Token Accuracy: 0.3301, Sequence Accuracy: 0.0021\n",
      "Epoch 2/15\n",
      "Train Loss: 3.7855\n",
      "Val Loss: 3.0918, BLEU: 0.1056, Perplexity: 22.02, CER: 0.5328\n",
      "Token Accuracy: 0.3546, Sequence Accuracy: 0.0010\n",
      "Epoch 3/15\n",
      "Train Loss: 3.3974\n",
      "Val Loss: 2.9166, BLEU: 0.1442, Perplexity: 18.48, CER: 0.4755\n",
      "Token Accuracy: 0.3874, Sequence Accuracy: 0.0038\n",
      "Epoch 4/15\n",
      "Train Loss: 3.1301\n",
      "Val Loss: 2.8530, BLEU: 0.1554, Perplexity: 17.34, CER: 0.4987\n",
      "Token Accuracy: 0.3778, Sequence Accuracy: 0.0004\n",
      "Epoch 5/15\n",
      "Train Loss: 2.9305\n",
      "Val Loss: 2.7733, BLEU: 0.1694, Perplexity: 16.01, CER: 0.5123\n",
      "Token Accuracy: 0.3786, Sequence Accuracy: 0.0006\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T07:21:39.842788Z",
     "iopub.status.busy": "2025-09-25T07:21:39.842480Z",
     "iopub.status.idle": "2025-09-25T07:34:45.520087Z",
     "shell.execute_reply": "2025-09-25T07:34:45.519464Z",
     "shell.execute_reply.started": "2025-09-25T07:21:39.842762Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting Urdu to Roman Transliteration Experiments\n",
      "============================================================\n",
      "Loading data...\n",
      "Loading data from urdu_ghazals_rekhta dataset...\n",
      "Loaded 21003 text pairs\n",
      "Preprocessing and filtering data...\n",
      "After preprocessing: 20893 pairs\n",
      "Creating data splits...\n",
      "Data split - Train: 10446 (50.0%), Val: 5223 (25.0%), Test: 5224 (25.0%)\n",
      "Train samples: 10446\n",
      "Validation samples: 5223\n",
      "Test samples: 5224\n",
      "Creating tokenizers...\n",
      "Urdu tokenizer vocabulary size: 512\n",
      "Roman tokenizer vocabulary size: 512\n",
      "\n",
      "Teacher Forcing Setup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use teacher forcing during training? (y/n, default y):  y\n",
      "Enter teacher forcing ratio [0.0-1.0] (default 0.5):  0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using teacher forcing ratio: 0.5\n",
      "\n",
      "==================================================\n",
      "Running experiment: baseline\n",
      "Config: {'name': 'baseline', 'embed_dim': 128, 'hidden_dim': 256, 'dropout': 0.1, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 15, 'teacher_forcing_ratio': 0.5, 'decoder_word_dropout': 0.1, 'max_length': 60, 'warmup_epochs': 2}\n",
      "==================================================\n",
      "Epoch 1/15\n",
      "Train Loss: 5.2388 (TF=0.50, LR=0.000500)\n",
      "Val Loss: 4.8335, BLEU: 0.0000, Perplexity: 125.65, CER: 0.7221\n",
      "Token Accuracy: 0.1233, Sequence Accuracy: 0.0000\n",
      "Epoch 2/15\n",
      "Train Loss: 4.7031 (TF=0.47, LR=0.001000)\n",
      "Val Loss: 4.4766, BLEU: 0.0012, Perplexity: 87.94, CER: 0.6760\n",
      "Token Accuracy: 0.1604, Sequence Accuracy: 0.0000\n",
      "Epoch 3/15\n",
      "Train Loss: 4.3509 (TF=0.43, LR=0.001000)\n",
      "Val Loss: 4.1955, BLEU: 0.0083, Perplexity: 66.39, CER: 0.6326\n",
      "Token Accuracy: 0.1756, Sequence Accuracy: 0.0000\n",
      "Epoch 4/15\n",
      "Train Loss: 4.0644 (TF=0.40, LR=0.001000)\n",
      "Val Loss: 3.9470, BLEU: 0.0123, Perplexity: 51.78, CER: 0.6131\n",
      "Token Accuracy: 0.1933, Sequence Accuracy: 0.0000\n",
      "Epoch 5/15\n",
      "Train Loss: 3.8219 (TF=0.37, LR=0.001000)\n",
      "Val Loss: 3.7613, BLEU: 0.0209, Perplexity: 43.01, CER: 0.6009\n",
      "Token Accuracy: 0.2083, Sequence Accuracy: 0.0000\n",
      "Epoch 6/15\n",
      "Train Loss: 3.6174 (TF=0.33, LR=0.001000)\n",
      "Val Loss: 3.6422, BLEU: 0.0287, Perplexity: 38.18, CER: 0.5682\n",
      "Token Accuracy: 0.2217, Sequence Accuracy: 0.0000\n",
      "Epoch 7/15\n",
      "Train Loss: 3.4569 (TF=0.30, LR=0.001000)\n",
      "Val Loss: 3.5763, BLEU: 0.0337, Perplexity: 35.74, CER: 0.5665\n",
      "Token Accuracy: 0.2280, Sequence Accuracy: 0.0002\n",
      "Epoch 8/15\n",
      "Train Loss: 3.3064 (TF=0.27, LR=0.001000)\n",
      "Val Loss: 3.5229, BLEU: 0.0376, Perplexity: 33.88, CER: 0.5591\n",
      "Token Accuracy: 0.2383, Sequence Accuracy: 0.0006\n",
      "Epoch 9/15\n",
      "Train Loss: 3.1797 (TF=0.23, LR=0.001000)\n",
      "Val Loss: 3.4719, BLEU: 0.0412, Perplexity: 32.20, CER: 0.5464\n",
      "Token Accuracy: 0.2454, Sequence Accuracy: 0.0006\n",
      "Epoch 10/15\n",
      "Train Loss: 3.0675 (TF=0.20, LR=0.001000)\n",
      "Val Loss: 3.4553, BLEU: 0.0491, Perplexity: 31.67, CER: 0.5391\n",
      "Token Accuracy: 0.2458, Sequence Accuracy: 0.0011\n",
      "Epoch 11/15\n",
      "Train Loss: 2.9691 (TF=0.17, LR=0.001000)\n",
      "Val Loss: 3.4477, BLEU: 0.0483, Perplexity: 31.43, CER: 0.5328\n",
      "Token Accuracy: 0.2559, Sequence Accuracy: 0.0013\n",
      "Epoch 12/15\n",
      "Train Loss: 2.8814 (TF=0.13, LR=0.001000)\n",
      "Val Loss: 3.4613, BLEU: 0.0513, Perplexity: 31.86, CER: 0.5266\n",
      "Token Accuracy: 0.2572, Sequence Accuracy: 0.0013\n",
      "Epoch 13/15\n",
      "Train Loss: 2.7980 (TF=0.10, LR=0.001000)\n",
      "Val Loss: 3.4471, BLEU: 0.0575, Perplexity: 31.41, CER: 0.5288\n",
      "Token Accuracy: 0.2597, Sequence Accuracy: 0.0011\n",
      "Epoch 14/15\n",
      "Train Loss: 2.7097 (TF=0.10, LR=0.001000)\n",
      "Val Loss: 3.4464, BLEU: 0.0597, Perplexity: 31.39, CER: 0.5250\n",
      "Token Accuracy: 0.2585, Sequence Accuracy: 0.0019\n",
      "Epoch 15/15\n",
      "Train Loss: 2.6351 (TF=0.10, LR=0.001000)\n",
      "Val Loss: 3.4656, BLEU: 0.0650, Perplexity: 32.00, CER: 0.5167\n",
      "Token Accuracy: 0.2580, Sequence Accuracy: 0.0019\n",
      "\n",
      "Final Test Results for baseline:\n",
      "Test Loss: 3.4794\n",
      "Test BLEU: 0.0630\n",
      "Test Perplexity: 32.44\n",
      "Test CER: 0.5180\n",
      "Test Token Accuracy: 0.2548\n",
      "Test Sequence Accuracy: 0.0019\n",
      "\n",
      "Sample Translations for baseline:\n",
      "Urdu:       \n",
      "Predicted: ai ha dil-e-dil hai bsh haish-e-sh\n",
      "Actual: ai hud dard-e-dil hai bahshish-e-dost\n",
      "--------------------------------------------------\n",
      "Urdu:      \n",
      "Predicted: zindage to zindag don den\n",
      "Actual: zindag ab to ik tamann de\n",
      "--------------------------------------------------\n",
      "Urdu:       \n",
      "Predicted: kaise hai chhup haiuput ke meo me\n",
      "Actual: kais baith hai chhup ke patto me\n",
      "--------------------------------------------------\n",
      "Urdu:         \n",
      "Predicted: 'urq' ikqlal badals hai ter ko\n",
      "Actual: 'firq' aksar badal kar bhes milt hai ko kfir\n",
      "--------------------------------------------------\n",
      "Urdu:          \n",
      "Predicted: haath to rakham pe kho kiiiv aa aa.e\n",
      "Actual: haath rakh de mir kho pe ki niid aa jaa.e\n",
      "--------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "EXPERIMENT SUMMARY\n",
      "================================================================================\n",
      "Experiment           BLEU     CER      Perplexity   Token Acc  Seq Acc   \n",
      "--------------------------------------------------------------------------------\n",
      "baseline             0.0630   0.5180   32.44        0.2548     0.0019    \n",
      "\n",
      "Best Model: baseline\n",
      "Best BLEU Score: 0.0630\n",
      "Best CER: 0.5180\n",
      "Best Token Accuracy: 0.2548\n",
      "Best Sequence Accuracy: 0.0019\n",
      "\n",
      "Experiments completed!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8313870,
     "sourceId": 13124318,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
